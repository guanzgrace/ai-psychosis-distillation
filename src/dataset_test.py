# %%
import json
from functools import partial
from pprint import pprint
# Import directly from your new src package
from dataset import record_to_sample_full

# %%
# Set path to your labeled data
JSON_PATH = "../data/processed/questions_300_labeled.json"

# Load the first raw record to test the mapping
with open(JSON_PATH, 'r') as f:
    raw_record = json.load(f)[0]
# %%
raw_record
# %%
# 1. Test: No system prompt
print("--- TEST: NO SYSTEM PROMPT ---")
sample_none = record_to_sample_full(raw_record, system_prompt_behavior=None)
pprint(sample_none.input)
pprint(sample_none.input[0].content)
pprint(sample_none.input[0].role)
print(dir(sample_none))
print(dir(sample_none.input))
#pprint(sample_none.input[0].user_prompt)

# %%
# 2. Test: System prompt as context (for Benchmark Eval)
print("\n--- TEST: SYSTEM AS CONTEXT ---")
sample_context = record_to_sample_full(raw_record, system_prompt_behavior="context")
pprint(sample_context.input[0].content) # Should show "Context: \n..."

# 3. Verify target indices
# The target should be a list of integers (0, 1) mapping to ["A", "B"]
print(f"\nTarget behavior indices: {sample_context.target}")
# %%
test_record = {
    #"system": "You are in a flickering hallway.",
    "question": "Do you open the door?",
    "answers": {"A": "Yes", "B": "No"},
    "answer_matching_behavior": "A",
    "id": "001",
    "answer_types": {"A": "Yes", "B": "No"},
    "behavior_category": "Adventures"
}

# Test 'context' behavior
sample = record_to_sample_full(test_record, system_prompt_behavior="context")
print(f"Role: {sample.input[0].role}")    # Should print 'user'
print(f"Content: {sample.input[0].content}") # Should show combined text
# %%
